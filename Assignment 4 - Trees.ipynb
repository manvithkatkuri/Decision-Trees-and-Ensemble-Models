{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6290349a",
   "metadata": {},
   "source": [
    "# Assignment 4 - Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c006e",
   "metadata": {},
   "source": [
    "In this assignment, you will delve into the world of decision trees and their ensemble counterparts. \n",
    "\n",
    "You'll work with the breast cancer dataset to understand how these algorithms can be utilized for classification tasks, and you'll also explore the importance of feature selection and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2d467",
   "metadata": {},
   "source": [
    "## Tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d7996",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Exploration: (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da5657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1: Data Loading and Exploration\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "\"\"\"\n",
    "Question: Load Breast Cancer Dataset (1 point)\n",
    "Using Scikit-learn's datasets module, load the breast cancer dataset.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Import the necessary function from Scikit-learn's datasets module.\n",
    "- Assign the feature data to a variable named `X` and target labels to a variable named `y`.\n",
    "- Remember to utilize the `load_breast_cancer()` function.\n",
    "\"\"\"\n",
    "\n",
    "data = \n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180c741",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568eb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2: Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "Question: Dataset Preprocessing (1 point)\n",
    "Using the loaded breast cancer dataset, divide it into training and testing sets.\n",
    "\n",
    "Hints:\n",
    "\n",
    "Utilize the train_test_split function.\n",
    "Remember to set test_size and random_state.\n",
    "\"\"\"\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe760e1",
   "metadata": {},
   "source": [
    "### 3. Decision Trees (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd12971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3: Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"\n",
    "Question: Decision Trees Implementation (4 points)\n",
    "Using the training data, implement a decision tree classifier and evaluate its accuracy on the testing data.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Initialize a DecisionTreeClassifier.\n",
    "- Train the classifier using the fit method on the training data.\n",
    "- Predict the labels of the testing data.\n",
    "- Calculate and print the accuracy of the classifier.\n",
    "- Visualize the decision tree using the plot_tree function. Make sure to use the feature_names from the data for clarity.\n",
    "\"\"\"\n",
    "\n",
    "# Decision Trees\n",
    "dt = \n",
    "#fit the tree dt\n",
    "y_pred = \n",
    "accuracy = \n",
    "print(f\"Decision Tree Accuracy: {accuracy*100:.2f}%\")\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dt, filled= , feature_names=)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e58af2",
   "metadata": {},
   "source": [
    "### 4. Random Forest (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55cc62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# part 4: Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\"\"\"\n",
    "Question: Random Forest Implementation (4 points)\n",
    "Using the training data, implement a random forest classifier and evaluate its accuracy on the testing data.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Initialize a RandomForestClassifier.\n",
    "- Train the classifier using the fit method on the training data.\n",
    "- Predict the labels of the testing data.\n",
    "- Calculate and print the accuracy of the classifier.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "rf = \n",
    "# fit the random forest rf\n",
    "y_pred = \n",
    "accuracy = \n",
    "print(f\"Random Forest Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Feature importances\n",
    "\n",
    "\"\"\"\n",
    "Question: Feature Importance Analysis (4 points)\n",
    "Using the trained Random Forest model, analyze and list down the importance of features in descending order.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Use the feature_importances_ attribute of the trained Random Forest model to get the importance of each feature.\n",
    "- Sort the features based on their importance in descending order.\n",
    "- Print the ranked features along with their importance values.\n",
    "\"\"\"\n",
    "\n",
    "# look for random forest on sklearn\n",
    "importances = \n",
    "# look for https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "indices = \n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(f\"{f+1}. {data.feature_names[indices[f]]} ({importances[indices[f]]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f7485",
   "metadata": {},
   "source": [
    "### 5. XGBoost (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95058882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "\"\"\"\n",
    "Question: Implementing XGBoost (4 points)\n",
    "Using the XGBoost library, train a classifier on the training data and evaluate its accuracy on the test set.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Initialize the XGBoost classifier using xgb.XGBClassifier().\n",
    "- Fit the classifier on the training data.\n",
    "- Predict the labels for the test set using the trained model.\n",
    "- Evaluate and print the accuracy of the predictions against the true test labels.\n",
    "\"\"\"\n",
    "\n",
    "clf = \n",
    "# fit the clf\n",
    "y_pred = \n",
    "accuracy = \n",
    "print(f\"XGBoost Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e816a03",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter Tuning (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a01b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\"\n",
    "Question: Hyperparameter Tuning for Random Forest (4 points)\n",
    "Using the provided param_grid for hyperparameters, apply Grid Search to find the optimal hyperparameters for a Random Forest classifier.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Utilize GridSearchCV with the given parameter grid param_grid and a 5-fold cross validation.\n",
    "- Fit the GridSearch on the training data.\n",
    "- After finding the best parameters, retrieve the best estimator using best_estimator_ attribute.\n",
    "- Predict the labels for the test set using the optimized Random Forest model.\n",
    "- Evaluate and print the accuracy of the predictions against the true test labels.\n",
    "\"\"\"\n",
    "\n",
    "# For this assignment, we'll only tune for Random Forest here\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "# define GridSearchCV with cv=5\n",
    "grid_search = \n",
    "grid_search.fit(X_train, y_train)\n",
    "# find best estimator\n",
    "best_rf = \n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(f\"Optimized Random Forest Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emailai",
   "language": "python",
   "name": "emailai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
